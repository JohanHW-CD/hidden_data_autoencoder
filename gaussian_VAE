
# # # # # # # # # # # # #
# While this works, it became useless for my purpose ^^
- Johan
# # # # # # # # # # # # #



# # # # # # # # # # # # #
# Import and Parameters
# # # # # # # # # # # # #

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
import numpy as np

# Neurons in each layer in encoder and decoder
hidden_dims = [64, 32]
# Latent dim is the number of features it targets finding.
latent_dim = 16        
learning_rate = 1e-4
epochs = 1000

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)


def generate_correlated_data(num_samples=1000, num_features=20, correlation=0.8):
    """
    VAE testing with normal distribution. It works, cool.

    Arguments:
    - num_samples: Number of rows (data points)
    - num_features: Number of columns (features)
    - correlation: Degree of correlation between features (0 = independent, 1 = identical)
    
    Returns:
    - NumPy array of shape (num_samples, num_features)
    """
    mean = np.zeros(num_features)
    cov = np.full((num_features, num_features), correlation)  # Fill with correlation value
    v = 100*np.random.rand() # good test
    #v = 1
    np.fill_diagonal(cov, v)  # Set diagonal to 1 (variance of each feature)
    
    
    # Sample from the multivariate normal distribution
    data = np.random.multivariate_normal(mean, cov, size=num_samples)
    
    return data.astype(np.float32)

# Generate synthetic test data
X = generate_correlated_data(num_samples=1000, num_features=20)


# Pandas Dataframe to np to torch tensor
#X_np = X.values.astype(np.float32)  # shape (num_samples, num_features)
X_np = X.astype(np.float32) 
X_tensor = torch.from_numpy(X_np)





input_dim = X_np.shape[1]  # number of features in X

# Dataloader module
batch_size = 64 # Larger is smoother and faster, but memory is limit
dataset = TensorDataset(X_tensor)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)


# # # # # # #
# Methods 
# # # # # # #


class Encoder(nn.Module):
    def __init__(self, input_dim, hidden_dims, latent_dim):
        super(Encoder, self).__init__()
        
        # Build a simple feed-forward network
        layers = []
        prev_dim = input_dim
        for h_dim in hidden_dims:
            # Sets a linear path between layers
            layers.append(nn.Linear(prev_dim, h_dim))
            # Sets a ReLU activation function in the neuron
            layers.append(nn.ReLU())
            prev_dim = h_dim

        # makes the hidden dims a module to be treated as one thing
        self.fc_hidden = nn.Sequential(*layers)
        
        # Final layers for mean and log-variance
        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)
        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)
        
    def forward(self, x):
        # x shape: (batch_size, input_dim)
        x = self.fc_hidden(x)
        mu = self.fc_mu(x)
        logvar = self.fc_logvar(x)
        return mu, logvar



class Decoder(nn.Module):
    def __init__(self, latent_dim, hidden_dims, output_dim):
        super(Decoder, self).__init__()
        
        layers = []
        prev_dim = latent_dim
        # Structured as just the reverse of the hidden_dims, no dimensional reduction intended
        for h_dim in reversed(hidden_dims):
            layers.append(nn.Linear(prev_dim, h_dim))
            layers.append(nn.ReLU())
            prev_dim = h_dim
        
        self.fc_hidden = nn.Sequential(*layers)
        
        # Final layer outputs reconstruction
        self.output_layer = nn.Linear(hidden_dims[0], output_dim)
        
    def forward(self, z):
        x = self.fc_hidden(z)
        x = self.output_layer(x)
        # Use 
        return x


class VAE(nn.Module):
    def __init__(self, input_dim, hidden_dims, latent_dim):
        super(VAE, self).__init__()
        self.encoder = Encoder(input_dim, hidden_dims, latent_dim)
        self.decoder = Decoder(latent_dim, hidden_dims, input_dim)

    def reparameterize(self, mu, logvar):
        """
        Reparameterization trick:
        z = mu + std * eps,
        where std = exp(0.5 * logvar) and eps ~ N(0, I)

        Note to self:
        Bernouli - while the data is pure binary, it's underlying method isn't
        Beta - could work for my stuff
        Laplace - could work for my stuff
        gaussian mixture - makes most sense to me and can approximate B and L

        currently normal gaussian as KL div is analytically fixed and often work.
        """
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)  # same shape as std
        return mu + eps * std

    def forward(self, x):
        mu, logvar = self.encoder(x)
        z = self.reparameterize(mu, logvar)
        x_recon = self.decoder(z)
        return x_recon, mu, logvar


# Helping functon
def loss_function(x, x_recon, mu, logvar):
    # For binary data BCE seems dope:
    recon_loss = F.mse_loss(x_recon, x, reduction='sum')
    # KL = -0.5 * sum(1 + logvar - mu^2 - e^(logvar))
    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return recon_loss + kl_div


# # # # # # #
# Training
# # # # # # #

# Initialize model & optimizer
model = VAE(input_dim, hidden_dims, latent_dim).to(device)
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training
model.train()
L = []
for epoch in range(epochs):
    train_loss = 0.0
    for batch_data in dataloader:
        x = batch_data[0].to(device)  # shape: (batch_size, input_dim)
        
        optimizer.zero_grad()
        
        x_recon, mu, logvar = model(x)
        loss = loss_function(x, x_recon, mu, logvar)
        
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item()
    
    # Average loss per sample (if you used 'sum' in loss_function)
    train_loss /= len(dataloader.dataset)
    L.append(train_loss)
    #print(f"Epoch [{epoch+1}/{epochs}], Loss: {train_loss:.4f}")



# # # # # # #
# Testing
# # # # # # #

model.eval()
X_torch = X_tensor.to(device)
with torch.no_grad():
    X_recon, _, _ = model(X_torch)
X_recon = X_recon.cpu().numpy()  # move back to CPU as a NumPy array

import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 5), tight_layout=True)

# Plot original vs. reconstructed sample
sample_idx = 1
axes[0].plot(X_np[sample_idx], label='Original')
axes[0].plot(X_recon[sample_idx], label='Reconstructed')
axes[0].legend()
axes[0].set_title("Original vs. Reconstructed Sample")

# Plot loss over epochs
axes[1].plot(L, label='Mean avg loss')
axes[1].legend()
axes[1].set_title("Loss over Epochs")

# Plot histogram comparison of one feature
feature_idx = 1  # Pick a feature to visualize
axes[2].hist(X[:, feature_idx], bins=50, alpha=0.5, label="Original")
axes[2].hist(X_recon[:, feature_idx], bins=50, alpha=0.5, label="Reconstructed")
axes[2].legend()
axes[2].set_title("Original vs. Reconstructed Feature")

plt.show()
