input_dim = real_data.shape[1]

# Define VAE model
# fc stands for fully connected, remember to add drop-out
class VAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super(VAE, self).__init__()
        
        # Encoder
        self.fc1 = nn.Linear(input_dim, 128)
        self.fc2_mu = nn.Linear(128, latent_dim)
        self.fc2_logvar = nn.Linear(128, latent_dim)
        
        # Decoder
        self.fc3 = nn.Linear(latent_dim, 128)
        self.fc4 = nn.Linear(128, input_dim)
        
    def encode(self, x):
        h = F.relu(self.fc1(x))
        mu = self.fc2_mu(h)
        logvar = self.fc2_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h))  # Bernoulli likelihood output
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)
        return recon_x, mu, logvar

def loss_function(recon_x, x, mu, logvar):
    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')
    KL = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KL

# Prepare DataLoader and VAE class
dataset = TensorDataset(real_data)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
latent_dim = 10
vae = VAE(input_dim, latent_dim)
optimizer = optim.Adam(vae.parameters(), lr=1e-3)



# Training loop
num_epochs = 304  
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
vae.to(device)

loss_history = []

for epoch in range(num_epochs):
    epoch_loss = 0
    for batch in dataloader:
        x = batch[0].to(device).float()
        optimizer.zero_grad()
        
        recon_x, mu, logvar = vae(x)
        
        loss = loss_function(recon_x, x, mu, logvar)
        epoch_loss += loss.item()
    
        loss.backward()
        optimizer.step()
    loss_history.append(epoch_loss / len(dataloader))

    if epoch % 300 == 0:  # Print loss every 300 epochs
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

# Function to compute imputation accuracy
def imputation_accuracy(original, imputed, masked):
    mask = (masked == 0)  # Positions where data was missing
    correct = (imputed[mask] == original[mask]).sum().item()
    total = mask.sum().item()
    return correct / total if total > 0 else 0

# Function for imputation
def impute_missing_values(vae, incomplete_x):
    vae.eval()  
    incomplete_x = incomplete_x.to(device).float()
    recon_x, _, _ = vae(incomplete_x)
    imputed_x = (recon_x > 0.5).float()  
    return imputed_x


# Function to visualize original, masked, and imputed samples
def visualize_imputation(original, masked, imputed):
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))
    
    image_shape = int(original.shape[0] ** 0.5) if int(original.shape[0] ** 0.5) ** 2 == original.shape[0] else original.shape[0]
    
    original = original.view(image_shape, -1).cpu().numpy()
    masked = masked.view(image_shape, -1).cpu().numpy()
    imputed = imputed.view(image_shape, -1).cpu().numpy()
    
    axes[0].imshow(original, cmap="gray")
    axes[0].set_title("Original")

    axes[1].imshow(masked, cmap="gray")
    axes[1].set_title("Masked (Missing Data)")

    axes[2].imshow(imputed, cmap="gray")
    axes[2].set_title("Imputed")

    plt.show()

# Select a sample and mask some values
sample_idx = 0
original_sample = real_data[sample_idx].clone()  
masked_sample = original_sample.clone()
masked_sample[::5] = 0  

# Perform imputation
vae.eval()  
imputed_sample = impute_missing_values(vae, masked_sample.unsqueeze(0)).squeeze(0)

# Compute accuracy
accuracy = imputation_accuracy(original_sample, imputed_sample, masked_sample)
print(f"Imputation Accuracy: {accuracy:.4f}")

# Plot loss convergence
plt.figure(figsize=(6, 4))
plt.plot(range(1, num_epochs + 1), loss_history, marker="o", linestyle="-")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training Loss Convergence")
plt.grid(True)
plt.show()

# Visualize results
visualize_imputation(original_sample, masked_sample, imputed_sample)
